{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "142zJWB4OdjSc3sfFy1qfsKN_e56g4zIc",
      "authorship_tag": "ABX9TyMnrKHl7UibazFzvP/zzAHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavme2020/Projrct-chatbot/blob/master/AI_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Chatbot**\n",
        "\n",
        "\n",
        "\n",
        "*   copy the repository from https://github.com/pallavme2020/Projrct-chatbot.git\n",
        "*   create the directory /content/V01\n",
        "\n",
        "paste the repository code in the directory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3oQ9D4aWOGYy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "481b5eb7"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "repo_url = 'https://github.com/pallavme2020/Projrct-chatbot.git'\n",
        "target_directory = '/content/V01'\n",
        "repo_name = repo_url.split('/')[-1].replace('.git', '') # Extracts 'Projrct-chatbot'\n",
        "full_repo_path = os.path.join(target_directory, repo_name)\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(target_directory, exist_ok=True)\n",
        "\n",
        "# Change to the target directory\n",
        "%cd {target_directory}\n",
        "\n",
        "# Check if the repository directory already exists and remove it\n",
        "if os.path.exists(full_repo_path):\n",
        "    print(f\"Removing existing directory: {full_repo_path}\")\n",
        "    shutil.rmtree(full_repo_path)\n",
        "    print(\"Existing repository directory removed.\")\n",
        "\n",
        "# Clone the repository\n",
        "print(f\"Cloning {repo_url} into {target_directory}...\")\n",
        "!git clone {repo_url}\n",
        "\n",
        "# Verify the content of the cloned repository\n",
        "print(f\"\\nContents of {target_directory}:\")\n",
        "!ls -F {target_directory}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for list all the contenet of the current directory"
      ],
      "metadata": {
        "id": "iVDEd0bCOzTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "id": "5Zbh7d_QISeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Installing all the pakages from the requirement.txt`\n",
        "* during the installation it will ask for the restart the colab then cancel it\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P9XKvOjyPD69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Install packages directly\n",
        "%cd /content/V01/Projrct-chatbot/\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(\"All packages installed in Colab environment!\")"
      ],
      "metadata": {
        "id": "P6HGxDORIUX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `installing the ollama`"
      ],
      "metadata": {
        "id": "MRDX03QJPSSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "print(\"Ollama installed successfully!\")"
      ],
      "metadata": {
        "id": "EmTRVu-JJPKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Running the ollama in the background`"
      ],
      "metadata": {
        "id": "Gecu0OrqPthk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Start Ollama server in background\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Start Ollama in background\n",
        "ollama_process = subprocess.Popen(\n",
        "    [\"ollama\", \"serve\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "print(\"Starting Ollama server in background...\")\n",
        "time.sleep(5)  # Wait for server to start\n",
        "\n",
        "# Check if Ollama is running\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:11434\")\n",
        "    print(\"✅ Ollama server is running!\")\n",
        "    print(f\"Status: {response.status_code}\")\n",
        "except:\n",
        "    print(\"⚠️ Ollama server might still be starting...\")\n",
        "    time.sleep(5)"
      ],
      "metadata": {
        "id": "CV5ViCRPJRsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Checking whether the ollama running in the background or not`"
      ],
      "metadata": {
        "id": "8tLHjKLVQC0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:11434"
      ],
      "metadata": {
        "id": "pDzNhYawKxUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `installing the ollama model`\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CzQDyLkqQUNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Pull your model (this will take time)\n",
        "!ollama pull granite4:micro-h\n",
        "\n",
        "# Or pull a smaller, faster model\n",
        "# !ollama pull phi\n",
        "# !ollama pull mistral"
      ],
      "metadata": {
        "id": "pH6QonB4KZYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `List all installed ollama models`"
      ],
      "metadata": {
        "id": "CvJFs6xnQriF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "jIcCT-zdK4XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "b4r2xckZK_rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `now run the Chatbot`\n",
        "\n"
      ],
      "metadata": {
        "id": "QEWufRKKQ3dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 chat_v3_proffesionalUI.py"
      ],
      "metadata": {
        "id": "JhxSFj_yUli_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Create the vector database `\n",
        "* using the documents in the document folder"
      ],
      "metadata": {
        "id": "szmNIAYczj8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 makedatabase.py\n"
      ],
      "metadata": {
        "id": "tXgRCyR1ZaP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "910ff6b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50c59f48"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/drive/MyDrive/Lsdyna-manuals/'\n",
        "destination_dir = '/content/V01/Projrct-chatbot/documents'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Searching for PDF files in: {source_dir}\")\n",
        "\n",
        "pdf_files_found = 0\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.lower().endswith('.pdf'):\n",
        "        source_file_path = os.path.join(source_dir, filename)\n",
        "        destination_file_path = os.path.join(destination_dir, filename)\n",
        "\n",
        "        if os.path.exists(source_file_path):\n",
        "            try:\n",
        "                shutil.copy2(source_file_path, destination_file_path)\n",
        "                print(f\"Copied '{filename}' to '{destination_dir}'\")\n",
        "                pdf_files_found += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error copying '{filename}': {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: Source file '{source_file_path}' not found. Please ensure the path is correct and your Drive is mounted.\")\n",
        "\n",
        "if pdf_files_found == 0:\n",
        "    print(\"No PDF files found in the source directory or no files were copied. Please check the source path and ensure your Google Drive is mounted.\")\n",
        "else:\n",
        "    print(f\"\\nSuccessfully copied {pdf_files_found} PDF file(s).\")\n",
        "\n",
        "# Verify the contents of the destination directory\n",
        "print(f\"\\nContents of {destination_dir}:\")\n",
        "!ls -F {destination_dir}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}